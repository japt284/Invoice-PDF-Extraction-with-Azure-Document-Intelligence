{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abeba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excel guardado en: C:\\Users\\z004zfhd\\OneDrive - Siemens AG\\Documentos\\Business Analytics - Machine Learning\\invoice_extraction.xlsx\n",
      "         Material   Quantity Total Gross Weight\n",
      "0  A5E02291075030  12.000,00          303,20 kg\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Invoice PDF extractor (Azure Document Intelligence)\n",
    "\n",
    "# --- Imports principales ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Azure SDK: credenciales---\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "\n",
    "# --- Azure endpoint + Key1 ---\n",
    "endpoint = \"https://eastus.api.cognitive.microsoft.com/\"\n",
    "key = \"256c36c92ab74418bdb2642d938fc263\"\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    # Normaliza texto (minúsculas y espacios) para comparar keys de KV pairs\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip()).lower()\n",
    "\n",
    "def _kv_to_dict(kv_pairs):\n",
    "    # Convierte key_value_pairs del modelo a diccionario {key_normalizada: value}\n",
    "    out = {}\n",
    "    if not kv_pairs:\n",
    "        return out\n",
    "    for kv in kv_pairs:\n",
    "        k = getattr(kv, \"key\", None)\n",
    "        v = getattr(kv, \"value\", None)\n",
    "        ktxt = (getattr(k, \"content\", \"\") or \"\").strip()\n",
    "        vtxt = (getattr(v, \"content\", \"\") or \"\").strip()\n",
    "        if ktxt and vtxt:\n",
    "            out[_norm(ktxt)] = vtxt\n",
    "    return out\n",
    "\n",
    "def extract_material_only_by_label(result):\n",
    "    # Material: primero intenta Key-Value (si el modelo lo detecta), si no usa regex del OCR\n",
    "    content = getattr(result, \"content\", \"\") or \"\"\n",
    "\n",
    "    kv_map = _kv_to_dict(getattr(result, \"key_value_pairs\", None))\n",
    "    for k, v in kv_map.items():\n",
    "        if (\"your article\" in k or \"your articleno\" in k) and \"no\" in k:\n",
    "            return v.strip() if v else None\n",
    "\n",
    "    # Regex tolerante a variaciones de OCR (misma línea o línea siguiente)\n",
    "    patterns = [\n",
    "        r\"your\\s*article\\s*no\\.?\\s*[: ]\\s*([A-Z0-9\\-\\/]+)\",\n",
    "        r\"your\\s*articleno\\.?\\s*[: ]\\s*([A-Z0-9\\-\\/]+)\",\n",
    "        r\"your\\s*article\\s*no\\.?\\s*[: ]?\\s*[\\r\\n]+\\s*([A-Z0-9\\-\\/]+)\",\n",
    "        r\"your\\s*articleno\\.?\\s*[: ]?\\s*[\\r\\n]+\\s*([A-Z0-9\\-\\/]+)\",\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, content, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def extract_total_gross_weight(content: str):\n",
    "    # Total gross weight: se extrae desde OCR (normalmente no viene como field estructurado)\n",
    "    m = re.search(\n",
    "        r\"total\\s+gross\\s+weight\\s*[:=]?\\s*([0-9]{1,3}(?:[.,][0-9]{3})*(?:[.,][0-9]+)?)\\s*kg\",\n",
    "        content,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    return (m.group(1).strip() + \" kg\") if m else None\n",
    "\n",
    "def fallback_quantity_from_content(content: str):\n",
    "    # Fallback: si no detecta una tabla, toma el primer número seguido de \"pieces\"\n",
    "    m = re.search(\n",
    "        r\"([0-9]{1,3}(?:[.,][0-9]{3})*(?:[.,][0-9]+)?)\\s*pieces\\b\",\n",
    "        content,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    return (m.group(1).strip() + \" pieces\") if m else None\n",
    "\n",
    "def extract_quantity_from_tables(result, material: str | None = None):\n",
    "    # Quantity: se toma desde tablas detectadas por Layout (columna 'Quantity')\n",
    "    tables = getattr(result, \"tables\", None) or []\n",
    "    if not tables:\n",
    "        return None\n",
    "\n",
    "    for t in tables:\n",
    "        grid = {}\n",
    "        for cell in (t.cells or []):\n",
    "            grid[(cell.row_index, cell.column_index)] = (cell.content or \"\").strip()\n",
    "\n",
    "        header_row = None\n",
    "        qty_col = None\n",
    "\n",
    "        # Identifica la fila header donde aparece \"quantity\"\n",
    "        for r in range(t.row_count):\n",
    "            row = [grid.get((r, c), \"\") for c in range(t.column_count)]\n",
    "            norm_row = [_norm(x) for x in row]\n",
    "            if any(\"quantity\" in x for x in norm_row):\n",
    "                header_row = r\n",
    "                for c, val in enumerate(norm_row):\n",
    "                    if \"quantity\" in val:\n",
    "                        qty_col = c\n",
    "                        break\n",
    "                break\n",
    "\n",
    "        if header_row is None or qty_col is None:\n",
    "            continue\n",
    "\n",
    "        # Si el material está en la tabla, intenta tomar la Quantity de esa fila\n",
    "        if material:\n",
    "            for r in range(header_row + 1, t.row_count):\n",
    "                row = [grid.get((r, c), \"\") for c in range(t.column_count)]\n",
    "                if any(material in x for x in row):\n",
    "                    q = grid.get((r, qty_col), \"\")\n",
    "                    return q.strip() if q else None\n",
    "\n",
    "        # Si no, toma la primera fila de datos con número\n",
    "        for r in range(header_row + 1, t.row_count):\n",
    "            q = grid.get((r, qty_col), \"\")\n",
    "            if q and re.search(r\"\\d\", q):\n",
    "                return q.strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "def analyze_invoice():\n",
    "    # --- Aqui vas a poner el URL de los PDFs a analizar---\n",
    "    invoicePath = r\"C:\\Users\\z004zfhd\\OneDrive - Siemens AG\\Documentos\\Business Analytics - Machine Learning\\Invoice 202410882.pdf\"\n",
    "    if not os.path.exists(invoicePath):\n",
    "        raise FileNotFoundError(invoicePath)\n",
    "\n",
    "    \n",
    "    client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    # --- Analiza con prebuilt-layout ---\n",
    "    with open(invoicePath, \"rb\") as f:\n",
    "        poller = client.begin_analyze_document(\n",
    "            model_id=\"prebuilt-layout\",\n",
    "            analyze_request=f,\n",
    "            content_type=\"application/pdf\",\n",
    "            features=[DocumentAnalysisFeature.KEY_VALUE_PAIRS],\n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "    content = getattr(result, \"content\", \"\") or \"\"\n",
    "\n",
    "    # --- Extracción de campos ---\n",
    "    material = extract_material_only_by_label(result)\n",
    "    quantity = extract_quantity_from_tables(result, material=material) or fallback_quantity_from_content(content)\n",
    "    total_gross_weight = extract_total_gross_weight(content)\n",
    "\n",
    "    # --- DataFrame + Excel ---\n",
    "    df = pd.DataFrame([{\n",
    "        \"Material\": material,\n",
    "        \"Quantity\": quantity,\n",
    "        \"Total Gross Weight\": total_gross_weight\n",
    "    }])\n",
    "\n",
    "    output_path = r\"C:\\Users\\z004zfhd\\OneDrive - Siemens AG\\Documentos\\Business Analytics - Machine Learning\\invoice_extraction.xlsx\"\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "    print(\"Excel guardado en:\", output_path)\n",
    "    print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_invoice()\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419760f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Item No    Quantity Gross weight\n",
      "0  L1V30361994011  20.800 pcs  1.300,00 kg\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Azure Document Intelligence - Extract (DN PDF):\n",
    "# Extrae: Item No, Quantity, Gross weight\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Azure SDK\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "\n",
    "# Endpoint y API Key\n",
    "endpoint = \"https://eastus.api.cognitive.microsoft.com/\"\n",
    "key = \"256c36c92ab74418bdb2642d938fc263\"\n",
    "\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    # Normaliza texto para comparar headers de tablas\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip()).lower()\n",
    "\n",
    "\n",
    "def extract_gross_weight(content: str):\n",
    "    \"\"\"\n",
    "    Extrae Gross Weight desde el OCR del documento\n",
    "    \"\"\"\n",
    "    if not content:\n",
    "        return None\n",
    "\n",
    "    m = re.search(\n",
    "        r\"gross\\s*weight\\s*[:=]?\\s*([0-9]{1,3}(?:[.,][0-9]{3})*(?:[.,][0-9]+)?)\\s*kg\",\n",
    "        content,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    return (m.group(1).strip() + \" kg\") if m else None\n",
    "\n",
    "\n",
    "def extract_itemno_quantity_from_tables(result):\n",
    "    \"\"\"\n",
    "    Extrae Item No y Quantity desde tablas detectadas por prebuilt-layout.\n",
    "    - Detecta header con 'Item No' y 'Quantity'\n",
    "    - Toma la primera fila de datos debajo del header\n",
    "    \"\"\"\n",
    "    tables = getattr(result, \"tables\", None) or []\n",
    "    if not tables:\n",
    "        return None, None\n",
    "\n",
    "    for t in tables:\n",
    "\n",
    "        # Construye matriz de celdas detectadas\n",
    "        grid = {}\n",
    "        for cell in (t.cells or []):\n",
    "            grid[(cell.row_index, cell.column_index)] = (cell.content or \"\").strip()\n",
    "\n",
    "        header_row = None\n",
    "        qty_col = None\n",
    "        item_col = None\n",
    "\n",
    "        # Busca la fila header que contenga Item No y Quantity\n",
    "        for r in range(t.row_count):\n",
    "            row = [grid.get((r, c), \"\") for c in range(t.column_count)]\n",
    "            nrow = [_norm(x) for x in row]\n",
    "\n",
    "            has_qty = any(\"quantity\" in x for x in nrow)\n",
    "            has_item = any((\"item\" in x and \"no\" in x) for x in nrow)\n",
    "\n",
    "            if has_qty and has_item:\n",
    "                header_row = r\n",
    "                for c, val in enumerate(nrow):\n",
    "                    if qty_col is None and \"quantity\" in val:\n",
    "                        qty_col = c\n",
    "                    if item_col is None and (\"item\" in val and \"no\" in val):\n",
    "                        item_col = c\n",
    "                break\n",
    "\n",
    "        if header_row is None or qty_col is None or item_col is None:\n",
    "            continue\n",
    "\n",
    "        # Extrae la primera fila de datos debajo del header\n",
    "        for r in range(header_row + 1, t.row_count):\n",
    "            qty = grid.get((r, qty_col), \"\").strip()\n",
    "            item_no = grid.get((r, item_col), \"\").strip()\n",
    "\n",
    "            if qty or item_no:\n",
    "                return (item_no if item_no else None), (qty if qty else None)\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def analyze_dn():\n",
    "\n",
    "    dnPath = r\"C:\\Users\\z004zfhd\\OneDrive - Siemens AG\\Documentos\\Business Analytics - Machine Learning\\DN 45759.pdf\"\n",
    "\n",
    "    # Validación existencia archivo\n",
    "    if not os.path.exists(dnPath):\n",
    "        raise FileNotFoundError(dnPath)\n",
    "\n",
    "    # Inicializa cliente Azure Document Intelligence\n",
    "    client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    # Analiza documento usando modelo Layout (tablas + texto)\n",
    "    with open(dnPath, \"rb\") as f:\n",
    "        poller = client.begin_analyze_document(\n",
    "            model_id=\"prebuilt-layout\",\n",
    "            analyze_request=f,\n",
    "            content_type=\"application/pdf\",\n",
    "            features=[DocumentAnalysisFeature.KEY_VALUE_PAIRS],\n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "    content = getattr(result, \"content\", \"\") or \"\"\n",
    "\n",
    "    # 1) Item No y Quantity desde tablas\n",
    "    item_no, quantity = extract_itemno_quantity_from_tables(result)\n",
    "\n",
    "    # 2) Gross weight desde texto OCR\n",
    "    gross_weight = extract_gross_weight(content)\n",
    "\n",
    "    # Construcción DataFrame\n",
    "    data = {\n",
    "        \"Item No\": [item_no],\n",
    "        \"Quantity\": [quantity],\n",
    "        \"Gross weight\": [gross_weight]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Muestra resultado\n",
    "    print(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_dn()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
